{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Нейросеть СNN  для распознавания тематики книги по обложке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Conv2D, BatchNormalization, AveragePooling2D, Flatten, TimeDistributed\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "all_files = glob('allfiles\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_f = []\n",
    "for i in all_files:\n",
    "    all_f.append(i.replace('allfiles'+'\\\\',''))\n",
    "ff = pd.DataFrame(all_f, columns=['fname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ff - датафрейм чтобы проверить, что есть все файлы из загруженной таблицы; пустые записи удалим.\n",
    "\n",
    "загрузим заранее подготовленный файл с классами и номером изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>medicine</th>\n",
       "      <th>music</th>\n",
       "      <th>mystery and detective stories</th>\n",
       "      <th>recipes</th>\n",
       "      <th>religion</th>\n",
       "      <th>romance</th>\n",
       "      <th>science</th>\n",
       "      <th>science fiction</th>\n",
       "      <th>cover_id</th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575546.0</td>\n",
       "      <td>575546.jpg</td>\n",
       "      <td>allfiles\\575546.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981419.0</td>\n",
       "      <td>1981419.jpg</td>\n",
       "      <td>allfiles\\1981419.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>905279.0</td>\n",
       "      <td>905279.jpg</td>\n",
       "      <td>allfiles\\905279.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1321813.0</td>\n",
       "      <td>1321813.jpg</td>\n",
       "      <td>allfiles\\1321813.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2964863.0</td>\n",
       "      <td>2964863.jpg</td>\n",
       "      <td>allfiles\\2964863.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   children  fantasy  medicine  music  mystery and detective stories  recipes  \\\n",
       "0       1.0      1.0       0.0    0.0                            0.0      0.0   \n",
       "1       1.0      0.0       0.0    0.0                            0.0      0.0   \n",
       "2       1.0      0.0       0.0    0.0                            0.0      0.0   \n",
       "3       1.0      0.0       0.0    0.0                            0.0      0.0   \n",
       "4       1.0      0.0       0.0    0.0                            0.0      0.0   \n",
       "\n",
       "   religion  romance  science  science fiction   cover_id         file  \\\n",
       "0       0.0      0.0      0.0              0.0   575546.0   575546.jpg   \n",
       "1       0.0      0.0      0.0              0.0  1981419.0  1981419.jpg   \n",
       "2       0.0      0.0      0.0              0.0   905279.0   905279.jpg   \n",
       "3       0.0      0.0      0.0              0.0  1321813.0  1321813.jpg   \n",
       "4       0.0      0.0      0.0              0.0  2964863.0  2964863.jpg   \n",
       "\n",
       "                   path  \n",
       "0   allfiles\\575546.jpg  \n",
       "1  allfiles\\1981419.jpg  \n",
       "2   allfiles\\905279.jpg  \n",
       "3  allfiles\\1321813.jpg  \n",
       "4  allfiles\\2964863.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample\n",
    "\n",
    "subj_list = ['children', 'fantasy','medicine', 'music','mystery and detective stories', \n",
    "             'recipes', 'religion', 'romance', 'science','science fiction']\n",
    "\n",
    "df = pd.read_csv('title_cover.csv')\n",
    "df['path'] = df.file.apply(lambda x: 'allfiles'+'\\\\'+x )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = df.merge(ff, left_on='file', right_on='fname', how='inner') \n",
    "# inner,  чтобы взять те файлы, которые точно есть и папке с файлами и в df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subj_new = ['children', 'fantasy','medicine', 'music','mystery and detective stories', \n",
    "             'religion', 'romance', 'science','science fiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_b = books[subj_new].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_lst = []\n",
    "for i in range(0, len(subj_new)):\n",
    "    w_lst.append(np.around(all_b[i]/all_b[0], decimals=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.7, 0.6, 1.4, 0.8, 3.4, 4.3, 4.1, 1.4]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = books['path']\n",
    "y = books[subj_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=888, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xtst, ytr, ytst = list(np.array(X_train)), list(np.array(X_test)), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28891"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)  # размер входного изображения сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path, target_size=IMG_SIZE):\n",
    "    img = load_img(path)  # загрузка и масштабирование изображения\n",
    "    array = img_to_array(img)\n",
    "    return preprocess_input(array)  # предобработка для ResNet50\n",
    "\n",
    "# генератор для последовательного чтения обучающих данных с диска\n",
    "def fit_generator(files, yy ,  batch_size = 32):    \n",
    "    while True:\n",
    "        #shuffle(files)\n",
    "        for k in range(len(files) // batch_size):\n",
    "            i = k * batch_size\n",
    "            j = i + batch_size\n",
    "            if j > len(files):\n",
    "                j = - j % len(files)               \n",
    "                \n",
    "            x = np.array([load_image(path) for path in files[i:j]])\n",
    "            y = yy[i:j]\n",
    "            #print(i, j)\n",
    "            #print(len(x))\n",
    "            #print(y)           \n",
    "            yield (x, y)\n",
    "\n",
    "# генератор последовательного чтения тестовых данных с диска\n",
    "def predict_generator(files):\n",
    "    while True:\n",
    "        for path in files:\n",
    "            yield np.array([load_image(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(1, 11):\n",
    "    subplot = fig.add_subplot(i // 5 + 1, 5, i)\n",
    "    plt.imshow(plt.imread(Xtr[i]));\n",
    "    book_title = []\n",
    "    if ytr[i] !=0:\n",
    "            #print(j, subj_list[j])\n",
    "        book_title.append('religion')\n",
    "    subplot.set_title('%s' %  str(book_title)); # поправить вывод названия\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_model -  объект класса keras.models.Model (Functional Model)\n",
    "base_model = ResNet50(include_top = True,\n",
    "                   weights = 'imagenet',\n",
    "                   input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# фиксируем все веса предобученной сети\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output \n",
    "x = keras.layers.Dropout(0.3) (x)\n",
    "x = keras.layers.Dense(200, activation = 'relu') (x) # было 100\n",
    "#x = keras.layers.Dropout(0.3) (x)\n",
    "x = keras.layers.Dense(9,  # 9 выходов\n",
    "                activation='sigmoid',  # функция активации  \n",
    "                )(x) \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='binary_crossentropy',  metrics=['accuracy'])\n",
    "checkp = ModelCheckpoint(filepath='weights.best.cover.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_val_split = 100  # число изображений в валидационной выборке\n",
    "validation_data = next(fit_generator(Xtr[:train_val_split],ytr[:train_val_split], train_val_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.6171 - acc: 0.8610\n",
      "Epoch 00001: val_loss improved from inf to 0.49098, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 23s 465ms/step - loss: 0.6146 - acc: 0.8615 - val_loss: 0.4910 - val_acc: 0.8856\n",
      "Epoch 2/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8866\n",
      "Epoch 00002: val_loss improved from 0.49098 to 0.34128, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 444ms/step - loss: 0.3918 - acc: 0.8866 - val_loss: 0.3413 - val_acc: 0.8856\n",
      "Epoch 3/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3299 - acc: 0.8869\n",
      "Epoch 00003: val_loss improved from 0.34128 to 0.32699, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.3299 - acc: 0.8869 - val_loss: 0.3270 - val_acc: 0.8856\n",
      "Epoch 4/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.8869\n",
      "Epoch 00004: val_loss improved from 0.32699 to 0.32335, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.3211 - acc: 0.8869 - val_loss: 0.3234 - val_acc: 0.8856\n",
      "Epoch 5/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.8870\n",
      "Epoch 00005: val_loss improved from 0.32335 to 0.31887, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 0.3200 - acc: 0.8870 - val_loss: 0.3189 - val_acc: 0.8856\n",
      "Epoch 6/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.8875\n",
      "Epoch 00006: val_loss improved from 0.31887 to 0.31407, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 0.3181 - acc: 0.8874 - val_loss: 0.3141 - val_acc: 0.8856\n",
      "Epoch 7/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3127 - acc: 0.8878\n",
      "Epoch 00007: val_loss improved from 0.31407 to 0.31067, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 0.3125 - acc: 0.8877 - val_loss: 0.3107 - val_acc: 0.8867\n",
      "Epoch 8/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.8886\n",
      "Epoch 00008: val_loss did not improve\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 0.3088 - acc: 0.8886 - val_loss: 0.3111 - val_acc: 0.8889\n",
      "Epoch 9/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3034 - acc: 0.8902\n",
      "Epoch 00009: val_loss improved from 0.31067 to 0.30958, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 0.3032 - acc: 0.8902 - val_loss: 0.3096 - val_acc: 0.8900\n",
      "Epoch 10/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.3005 - acc: 0.8907\n",
      "Epoch 00010: val_loss did not improve\n",
      "50/50 [==============================] - 21s 427ms/step - loss: 0.3004 - acc: 0.8908 - val_loss: 0.3109 - val_acc: 0.8822\n",
      "Epoch 11/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2982 - acc: 0.8927\n",
      "Epoch 00011: val_loss improved from 0.30958 to 0.30877, saving model to weights.best.cover.hdf5\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 0.2984 - acc: 0.8926 - val_loss: 0.3088 - val_acc: 0.8822\n",
      "Epoch 12/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2961 - acc: 0.8923\n",
      "Epoch 00012: val_loss did not improve\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 0.2961 - acc: 0.8923 - val_loss: 0.3104 - val_acc: 0.8789\n",
      "Epoch 13/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.8931\n",
      "Epoch 00013: val_loss did not improve\n",
      "50/50 [==============================] - 22s 432ms/step - loss: 0.2935 - acc: 0.8931 - val_loss: 0.3151 - val_acc: 0.8767\n",
      "Epoch 14/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2930 - acc: 0.8928\n",
      "Epoch 00014: val_loss did not improve\n",
      "50/50 [==============================] - 22s 432ms/step - loss: 0.2930 - acc: 0.8928 - val_loss: 0.3188 - val_acc: 0.8756\n",
      "Epoch 15/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.8940\n",
      "Epoch 00015: val_loss did not improve\n",
      "50/50 [==============================] - 22s 430ms/step - loss: 0.2893 - acc: 0.8940 - val_loss: 0.3175 - val_acc: 0.8756\n",
      "Epoch 16/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.8942\n",
      "Epoch 00016: val_loss did not improve\n",
      "50/50 [==============================] - 22s 432ms/step - loss: 0.2880 - acc: 0.8943 - val_loss: 0.3218 - val_acc: 0.8756\n",
      "Epoch 17/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.8938\n",
      "Epoch 00017: val_loss did not improve\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 0.2885 - acc: 0.8938 - val_loss: 0.3245 - val_acc: 0.8767\n",
      "Epoch 18/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.8940\n",
      "Epoch 00018: val_loss did not improve\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 0.2871 - acc: 0.8941 - val_loss: 0.3291 - val_acc: 0.8756\n",
      "Epoch 19/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.8944\n",
      "Epoch 00019: val_loss did not improve\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 0.2862 - acc: 0.8945 - val_loss: 0.3247 - val_acc: 0.8733\n",
      "Epoch 20/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.8964\n",
      "Epoch 00020: val_loss did not improve\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 0.2806 - acc: 0.8963 - val_loss: 0.3275 - val_acc: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da677f5710>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# запускаем процесс обучения\n",
    "model.fit_generator(fit_generator(Xtr[train_val_split:], ytr[train_val_split:], 100),  # данные читаем функцией-генератором\n",
    "        steps_per_epoch=50,  # число вызовов генератора за эпоху\n",
    "        epochs=20,# число эпох обучения\n",
    "        class_weight =  np.array(w_lst)*100,\n",
    "        validation_data=validation_data, callbacks = [checkp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights.best.cover.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = model.predict_generator(predict_generator(Xtst), len(ytst), max_queue_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07815489, 0.05016572, 0.04485714, ..., 0.0547547 , 0.3870651 ,\n",
       "        0.04640883],\n",
       "       [0.06333856, 0.0729937 , 0.04096822, ..., 0.12319621, 0.31123066,\n",
       "        0.0573553 ],\n",
       "       [0.07813549, 0.02817815, 0.05179563, ..., 0.00591414, 0.7809319 ,\n",
       "        0.02737962],\n",
       "       ...,\n",
       "       [0.0694932 , 0.12457986, 0.03562356, ..., 0.29124844, 0.08517682,\n",
       "        0.13077694],\n",
       "       [0.06647351, 0.08342028, 0.03914815, ..., 0.14669524, 0.19429107,\n",
       "        0.08115155],\n",
       "       [0.07825997, 0.02759339, 0.05210314, ..., 0.00540175, 0.79066473,\n",
       "        0.02679958]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       682\n",
      "          1       0.00      0.00      0.00      1156\n",
      "          2       0.00      0.00      0.00       411\n",
      "          3       0.00      0.00      0.00       957\n",
      "          4       0.00      0.00      0.00       510\n",
      "          5       0.42      0.01      0.03      2266\n",
      "          6       0.74      0.08      0.14      2887\n",
      "          7       0.42      0.43      0.42      2774\n",
      "          8       0.00      0.00      0.00       970\n",
      "\n",
      "avg / total       0.34      0.11      0.13     12613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from pylab import rcParams\n",
    "\n",
    "summary = classification_report(ytst, y_pred)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(1, 11):\n",
    "    subplot = fig.add_subplot(i // 5 + 1, 5, i)\n",
    "    plt.imshow(plt.imread(Xtr[i]));\n",
    "    book_title = ()\n",
    "    if ytr[i] !=0:\n",
    "        book_title = 'religion. '+ str(np.around(pred[i],decimals= 2))\n",
    "    else:\n",
    "        book_title = str(np.around(pred[i], decimals = 2))\n",
    "    subplot.set_title(book_title); # поправить вывод названия\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class = np.around(pred)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (10, 7)\n",
    "\n",
    "summary = classification_report(ytst, pred_class)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(ytst, pred)\n",
    "fig = plt.figure()\n",
    "plt.plot( fpr, tpr)    \n",
    "plt.plot([0, 1], [0, 1])\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Book Subject classification. Religion')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig('Book Subject classification LSTM', dpi = 300, bbox_inches='tight')\n",
    "print();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
